{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taller #4: Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "stopwords_sp = stopwords.words('spanish')\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Punto 1: Pre-Procesamiento\n",
    "\n",
    "-  Leer el archivo `dialogos.csv` usando `pandas`\n",
    "-  Crear una nueva columna con el texto en minúscula, sin caracteres especiales ni números y sin palabras vacias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Locución</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Francamente no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lo del canadiense. Por favor, como que vosotro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tienes razón. A lo mejor así te liberas de tu ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pues, tú sabrás</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Para mí que fue Krieger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>Yo qué sé, digo yo qué será</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>Lo han entendido mal. Las joyas que venden en ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>Oooo... Me llamo Vivian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>¿De dónde? ¿Del coño de tu madre?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>Ah, sí esto podría funcionar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>959 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Locución\n",
       "0                                       Francamente no\n",
       "1    Lo del canadiense. Por favor, como que vosotro...\n",
       "2    Tienes razón. A lo mejor así te liberas de tu ...\n",
       "3                                      Pues, tú sabrás\n",
       "4                              Para mí que fue Krieger\n",
       "..                                                 ...\n",
       "954                        Yo qué sé, digo yo qué será\n",
       "955  Lo han entendido mal. Las joyas que venden en ...\n",
       "956                            Oooo... Me llamo Vivian\n",
       "957                  ¿De dónde? ¿Del coño de tu madre?\n",
       "958                       Ah, sí esto podría funcionar\n",
       "\n",
       "[959 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dialogos.csv')\n",
    "df # Datos en bruto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sentence(lista):\n",
    "    sent_str = \"\"\n",
    "    for i in lista:\n",
    "        sent_str += str(i) + \"   \"\n",
    "        sent_str = sent_str[:-1]\n",
    "    return sent_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(word_list): \n",
    "    processed_word_list = [] \n",
    "    for word in word_list: \n",
    "        word = word.lower() # minúscula\n",
    "        if word not in stopwords_sp: \n",
    "            processed_word_list.append(word) \n",
    "    return processed_word_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Locución</th>\n",
       "      <th>pre-procesado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Francamente no</td>\n",
       "      <td>francamente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lo del canadiense. Por favor, como que vosotro...</td>\n",
       "      <td>canadiense  favor  tiraríais  allí  si  pudies...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tienes razón. A lo mejor así te liberas de tu ...</td>\n",
       "      <td>razón  mejor  así  liberas  energía  nagativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pues, tú sabrás</td>\n",
       "      <td>pues  sabrás</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Para mí que fue Krieger</td>\n",
       "      <td>krieger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>Yo qué sé, digo yo qué será</td>\n",
       "      <td>sé  digo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>Lo han entendido mal. Las joyas que venden en ...</td>\n",
       "      <td>entendido  mal  joyas  venden  canales  siquie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>Oooo... Me llamo Vivian</td>\n",
       "      <td>oooo  llamo  vivian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>¿De dónde? ¿Del coño de tu madre?</td>\n",
       "      <td>dónde  coño  madre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>Ah, sí esto podría funcionar</td>\n",
       "      <td>ah  podría  funcionar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>959 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Locución  \\\n",
       "0                                       Francamente no   \n",
       "1    Lo del canadiense. Por favor, como que vosotro...   \n",
       "2    Tienes razón. A lo mejor así te liberas de tu ...   \n",
       "3                                      Pues, tú sabrás   \n",
       "4                              Para mí que fue Krieger   \n",
       "..                                                 ...   \n",
       "954                        Yo qué sé, digo yo qué será   \n",
       "955  Lo han entendido mal. Las joyas que venden en ...   \n",
       "956                            Oooo... Me llamo Vivian   \n",
       "957                  ¿De dónde? ¿Del coño de tu madre?   \n",
       "958                       Ah, sí esto podría funcionar   \n",
       "\n",
       "                                         pre-procesado  \n",
       "0                                        francamente    \n",
       "1    canadiense  favor  tiraríais  allí  si  pudies...  \n",
       "2      razón  mejor  así  liberas  energía  nagativa    \n",
       "3                                       pues  sabrás    \n",
       "4                                            krieger    \n",
       "..                                                 ...  \n",
       "954                                         sé  digo    \n",
       "955  entendido  mal  joyas  venden  canales  siquie...  \n",
       "956                              oooo  llamo  vivian    \n",
       "957                               dónde  coño  madre    \n",
       "958                            ah  podría  funcionar    \n",
       "\n",
       "[959 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pre-proc'] = [re.sub(r'[\\W\\d_]+',' ', str(frase)) for frase in df['Locución']]\n",
    "df['pre-procesado'] = \"\"\n",
    "\n",
    "for i,frase in enumerate(df['pre-proc']):\n",
    "    token = frase.split()\n",
    "    sinvacias = remove_stopwords(token)\n",
    "    df['pre-procesado'][i] = sentence(sinvacias)\n",
    "newdf = df[['Locución','pre-procesado']]\n",
    "newdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Punto 2: Representación vectorial\n",
    "\n",
    "-  Crear una bolsa de palabras (BoW) del corpus usando la columna pre-procesada\n",
    "-  ¿Cuántas palabras hay en el vocabulario? (Usando la función de `sklearn`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BoW usando la columna pre-procesada\n",
    "count_vect = CountVectorizer()\n",
    "bow = count_vect.fit_transform(newdf['pre-procesado'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2115"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count_vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Punto 3: 🤔\n",
    "\n",
    "-  ¿En qué casos es buena idea tomar en la cuenta la frecuencia de las palabras para la bolsa de palabras?\n",
    "En casos en los que queremos conocer cuál es el tema principal de un texto, por ejemplo en un texto de quejas de servicio al cliente, al tener las palabras que más frecuencia tienen podemos tener un acercamiento a lo que los clientes mencionan mas en sus quejas. \n",
    "-  ¿Cuándo es una mejor idea usar una bolsa de n-gramas en vez de una bolsa de palabras?\n",
    "Cuando se requiere un contexto, por ejemplo al hacer análisis de sentimientos, se requiere entrenar un modelo usando diferentes grupos de palabras ya que la posición de las palabras puede afectar el significado, así que su uso puede ser más útil que la bolsa de palabras para describir el texto.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BONUS Punto 4: 😜\n",
    "\n",
    "-  ¿A qué pertenecen los dialogos del primer punto? \n",
    "\"This dataset contains all utterances of two episodes of South Park (Latin American voices) and two episodes of Archer (Spanish voices)\" https://www.kaggle.com/mikahama/the-best-sarcasm-annotated-dataset-in-spanish "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
